{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"battleship\")))\n",
    "\n",
    "from agents import CodeSpotterModel\n",
    "from agents import DirectSpotterModel\n",
    "from run_spotter_benchmarks import load_data, benchmark_on_rounds\n",
    "\n",
    "df, rounds_questions_dict = load_data(\n",
    "        stages_path=\"/home/ubuntu/repo_battleship/temp/gold_annotations_partial.csv\",\n",
    "        rounds_path=\"/home/ubuntu/repo_battleship/battleship/experiments/collaborative/battleship-final-data/round.csv\",\n",
    "        goldAnnotations=[\"answer\", \"ambiguous\", \"contextual\", \"unanswerable\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We'll store the accuracy results in a dictionary:\n",
    "# Key: language model string\n",
    "# Value: list of accuracies [DirectSpotter, CodeSpotterModel]\n",
    "results = {}\n",
    "QUESTIONS = 5\n",
    "ROUNDS = 3\n",
    "\n",
    "spotter_models = [DirectSpotterModel, CodeSpotterModel]\n",
    "language_models = [\"openai/gpt-4o\", \"anthropic/claude-3.5-sonnet\", \"meta-llama/llama-3.3-70b-instruct\"]\n",
    "\n",
    "for llm in language_models:\n",
    "        results[llm] = []\n",
    "        for spotter in spotter_models:\n",
    "                print(f\"Benchmarking {spotter.__name__} with language model {llm}\")\n",
    "                accuracy, failed = benchmark_on_rounds(\n",
    "                        df=df,\n",
    "                        rounds_question_ids=rounds_questions_dict,\n",
    "                        model=spotter,\n",
    "                        model_string=llm,\n",
    "                        max_rounds=ROUNDS,\n",
    "                        max_questions=QUESTIONS,\n",
    "                        use_cache=False,\n",
    "                )\n",
    "                results[llm].append(accuracy)\n",
    "                print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the plot\n",
    "labels = language_models\n",
    "x = np.arange(len(labels))  # positions for language models on x-axis\n",
    "width = 0.35  # width of each bar\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# For each language model, the first element is for DirectSpotter and the second for CodeSpotterModel.\n",
    "direct = [results[l][0] for l in labels]\n",
    "code = [results[l][1] for l in labels]\n",
    "\n",
    "rects1 = ax.bar(x - width/2, direct, width, label='DirectSpotter')\n",
    "rects2 = ax.bar(x + width/2, code, width, label='CodeSpotterModel')\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy by Language Model and Spotter Model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "# Annotate bars with the accuracy values.\n",
    "def autolabel(rects):\n",
    "        for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                ax.annotate(f'{height:.2f}',\n",
    "                                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                                        xytext=(0, 3),  # vertical offset in points\n",
    "                                        textcoords=\"offset points\",\n",
    "                                        ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "battleship-7EcZJYqU-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
