{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "from battleship.agents import RandomCaptain, MAPCaptain, ProbabilisticCaptain, CodeSpotterModel\n",
    "from battleship.board import Board\n",
    "from battleship.game import BattleshipGame\n",
    "from battleship.agents import CacheMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_df = pd.read_csv(\"/home/ubuntu/repo_battleship/temp/gold_annotations_partial.csv\")\n",
    "round_df = pd.read_csv(\"/home/ubuntu/repo_battleship/battleship/experiments/collaborative/battleship-final-data/round.csv\")\n",
    "goldAnnotations=[\"answer\", \"ambiguous\", \"contextual\", \"unanswerable\"]\n",
    "\n",
    "board_ids = round_df[[\"id\", \"board_id\"]]\n",
    "\n",
    "filtered_stage_df = stage_df[\n",
    "    [\n",
    "        \"roundID\",\n",
    "        \"index\",\n",
    "        \"questionID\",\n",
    "        \"messageText\",\n",
    "        \"messageType\",\n",
    "        \"occTiles\",\n",
    "        \"goldAnswer\",\n",
    "    ]\n",
    "]\n",
    "df = filtered_stage_df.merge(\n",
    "    board_ids, left_on=\"roundID\", right_on=\"id\", how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_completed(hits, misses, occTiles, board_id):\n",
    "    def mask(board_array):\n",
    "        return (board_array != -1) & (board_array != 0)\n",
    "    if hits + misses < 40:\n",
    "        return True\n",
    "    else:\n",
    "        return np.all(mask(occTiles) == mask(Board.convert_to_numeric(Board.from_trial_id(board_id).to_symbolic_array())))\n",
    "\n",
    "question_counts_df = (\n",
    "    df[df[\"messageType\"] == \"question\"]\n",
    "    .groupby(\"roundID\")\n",
    "    .size()\n",
    "    .reset_index(name=\"question_number\")\n",
    ")\n",
    "\n",
    "df = df.merge(question_counts_df, on=\"roundID\", how=\"inner\")\n",
    "result = df.loc[df.groupby('roundID')['index'].idxmax()][['roundID','occTiles', 'board_id','question_number']]\n",
    "result = result[result[\"occTiles\"] != str(np.full((8, 8), -1).tolist()).replace(\" \", \"\")] #ugly!\n",
    "data = []\n",
    "for roundID, occTiles, board_id in zip(result[\"roundID\"], result[\"occTiles\"], result[\"board_id\"]):\n",
    "    occTiles = np.array(eval(occTiles))\n",
    "    misses = np.sum(occTiles == 0)\n",
    "    hits = np.sum((occTiles != -1) & (occTiles != 0))\n",
    "    data.append({\n",
    "        \"captainType\": \"human\",\n",
    "        \"boardId\": board_id,\n",
    "        \"hits\": hits,\n",
    "        \"misses\": misses,\n",
    "        \"gameCompleted\": game_completed(hits, misses, occTiles, board_id),\n",
    "        \"questionsAsked\": result[result[\"roundID\"] == roundID][\"question_number\"].values[0]\n",
    "    })\n",
    "human_results_df = pd.DataFrame(data)\n",
    "\n",
    "human_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "board_ids = [\"B\"+str(i).zfill(2) for i in range(1, 19)]\n",
    "captains = {\"RandomCaptain\": RandomCaptain(seed=42), \"MAPCaptain\":MAPCaptain(seed=42, n_samples=100), \"Probabilistic\":ProbabilisticCaptain(seed=42, q_prob=0.7, questions_remaining=15, model_string=\"openai/gpt-4o-mini\", cache_mode=CacheMode.WRITE_ONLY)}\n",
    "seeds = range(1,7+1)\n",
    "\n",
    "seeds = [1]\n",
    "board_ids = [\"B\"+str(i).zfill(2) for i in range(1, 4)]\n",
    "\n",
    "data = []\n",
    "for cap_name, captain in captains.items():\n",
    "    print(\"Starting with captain\", cap_name)\n",
    "    for idx, seed in enumerate(seeds):\n",
    "        for board_id in board_ids:\n",
    "            board = Board.from_trial_id(board_id)\n",
    "            game = BattleshipGame(\n",
    "                board_target=board,\n",
    "                captain=captain,\n",
    "                spotter=CodeSpotterModel(\n",
    "                                        board_id,\n",
    "                                        \"collaborative\",\n",
    "                                        cache_mode=CacheMode.WRITE_ONLY,\n",
    "                                        model_string=\"openai/gpt-4o\",\n",
    "                                        temperature=None,\n",
    "                                        ),\n",
    "            )\n",
    "            game.play()\n",
    "            hits = game.hits\n",
    "            misses = game.misses\n",
    "            data.append({\n",
    "                \"captainType\": cap_name,\n",
    "                \"boardId\": board_id,\n",
    "                \"hits\": hits,\n",
    "                \"misses\": misses,\n",
    "                \"gameCompleted\": game.is_won(),\n",
    "                \"questionsAsked\": game.question_count\n",
    "            })\n",
    "\n",
    "agent_results_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([human_results_df, agent_results_df])\n",
    "results_df[\"precision\"] = results_df[\"hits\"] / (results_df[\"hits\"] + results_df[\"misses\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average precision and fraction of games completed per captain type\n",
    "# Split human results into three groups based on questionsAsked\n",
    "human_mask = results_df[\"captainType\"] == \"human\"\n",
    "results_df_humans = results_df[human_mask].copy()\n",
    "\n",
    "conditions = [\n",
    "    results_df_humans[\"questionsAsked\"] < 5,\n",
    "    (results_df_humans[\"questionsAsked\"] >= 5) & (results_df_humans[\"questionsAsked\"] <= 10),\n",
    "    results_df_humans[\"questionsAsked\"] > 10\n",
    "]\n",
    "choices = [\"below 5\", \"between 5 and 10\", \"above 10\"]\n",
    "results_df_humans[\"question_group\"] = np.select(conditions, choices, default=\"unknown\")\n",
    "\n",
    "# Compute metrics for agent teams as before\n",
    "avg_precision_agents = results_df.groupby(\"captainType\")[\"precision\"].mean()\n",
    "frac_completed_agents = results_df.groupby(\"captainType\")[\"gameCompleted\"].mean()\n",
    "\n",
    "# Compute metrics for human groups split by questions asked\n",
    "avg_precision_humans = results_df_humans.groupby(\"question_group\")[\"precision\"].mean()\n",
    "frac_completed_humans = results_df_humans.groupby(\"question_group\")[\"gameCompleted\"].mean()\n",
    "\n",
    "# Combine the results for display\n",
    "avg_precision = pd.concat([avg_precision_agents, avg_precision_humans])\n",
    "frac_completed = pd.concat([frac_completed_agents, frac_completed_humans])\n",
    "\n",
    "avg_precision, frac_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create two side-by-side bar plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "avg_precision.plot(kind=\"bar\", ax=axes[0])\n",
    "axes[0].set_ylabel(\"Average Precision\")\n",
    "axes[0].set_title(\"Average Precision by Captain Type\")\n",
    "\n",
    "frac_completed.plot(kind=\"bar\", ax=axes[1])\n",
    "axes[1].set_ylabel(\"Fraction of Completed Games\")\n",
    "axes[1].set_title(\"Fraction of Games Completed by Captain Type\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "battleship-7EcZJYqU-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
