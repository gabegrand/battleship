{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkcETQfqsTDu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGaWl9GnHmxT"
      },
      "source": [
        "# Efficiency Comparisons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OOU59mcsV35m",
        "outputId": "3e218201-b69f-4994-c3a1-027363d02fc7"
      },
      "outputs": [],
      "source": [
        "#This cell generates the average EIG and validity percentage of each method in order to produce the first part of Table 1.\n",
        "from contextlib import ContextDecorator\n",
        "from collections import Counter\n",
        "from random import sample\n",
        "contexts = range(1,19)\n",
        "\n",
        "df_dict = {\"model\":[],\"sample_length\":[],\"attributes\":[],\"context\":[],\"max_eig\":[],\"valid\":[]}\n",
        "\n",
        "llm = pd.read_csv(\"llm_results.csv\")\n",
        "llm100 = pd.read_csv(\"llm100_results.csv\")\n",
        "sampling = pd.read_csv(\"sampling_results.csv\")\n",
        "hfppl = pd.read_csv(\"hfppl_results.csv\")\n",
        "\n",
        "#llm10\n",
        "modes = [\"ascii\",\"serial\",\"vision\"]\n",
        "for mode in modes:\n",
        "  llm_new = llm[llm[\"mode\"] == mode]\n",
        "  for context in contexts:\n",
        "    try:\n",
        "      mList = llm_new[llm_new[\"context\"] == context][\"eig\"].to_list()\n",
        "      max_eig = max(mList)\n",
        "      zero = Counter(mList)[0]/len(mList)\n",
        "    except:\n",
        "      max_eig = -0.0\n",
        "      zero = 1\n",
        "\n",
        "    df_dict[\"model\"].append(\"GPT4\")\n",
        "    df_dict[\"sample_length\"].append(\"10\")\n",
        "    df_dict[\"attributes\"].append(mode)\n",
        "    df_dict[\"context\"].append(context)\n",
        "    df_dict[\"max_eig\"].append(max_eig)\n",
        "    df_dict[\"valid\"].append(1-zero)\n",
        "    print(\"GPT4\", \"10\", mode, context, max_eig, zero)\n",
        "\n",
        "#llm100\n",
        "modes = [\"ascii\",\"serial\",\"vision\"]\n",
        "for mode in modes:\n",
        "  llm100_new = llm100[llm100[\"mode\"] == mode]\n",
        "  for context in contexts:\n",
        "    try:\n",
        "      mList = llm100_new[llm100_new[\"context\"] == context][\"eig\"].to_list()\n",
        "      max_eig = max(mList)\n",
        "      zero = sum([float(i) <= 0 for i in mList])/len(mList)\n",
        "    except IndexError:\n",
        "      max_eig = -0.0\n",
        "      zero = 1\n",
        "    df_dict[\"model\"].append(\"GPT4\")\n",
        "    df_dict[\"sample_length\"].append(\"100\")\n",
        "    df_dict[\"attributes\"].append(mode)\n",
        "    df_dict[\"context\"].append(context)\n",
        "    df_dict[\"max_eig\"].append(max_eig)\n",
        "    df_dict[\"valid\"].append(1-zero)\n",
        "    print(\"GPT4\", \"100\", mode, context, max_eig, zero)\n",
        "\n",
        "#hfppl\n",
        "information = [\"REGULAR\",\"COMBINED\"]\n",
        "particles = [1,3,5]\n",
        "for context in contexts:\n",
        "  hfppl_new = hfppl[hfppl[\"trial_id\"] == context]\n",
        "  for particle in particles:\n",
        "    for awareness in information:\n",
        "      try:\n",
        "        mList = hfppl_new[hfppl_new[\"particle_num\"] < particle][hfppl_new[\"model_type\"] == awareness][\"score\"].to_list()\n",
        "        max_eig = max(mList)\n",
        "        samples = len(hfppl_new[hfppl_new[\"particle_num\"] < particle][hfppl_new[\"model_type\"] == awareness])\n",
        "        zero = Counter(mList)[0]/len(mList)\n",
        "      except:\n",
        "        max_eig = -0.0\n",
        "      extra = \"(No board)\" if awareness == \"REGULAR\" else \"\"\n",
        "      df_dict[\"model\"].append(f'SMC Steering {extra}')\n",
        "      df_dict[\"sample_length\"].append(samples)\n",
        "      df_dict[\"attributes\"].append(f\"{awareness}_{particle}\")\n",
        "      df_dict[\"context\"].append(context)\n",
        "      df_dict[\"max_eig\"].append(max_eig)\n",
        "      df_dict[\"valid\"].append(1-zero)\n",
        "      print(f\"SMC Steering {extra}\", samples, f\"{awareness}_{particle}\",context,max_eig, zero)\n",
        "\n",
        "#sampling\n",
        "sampling_lengths = [10,100,1000,10000]\n",
        "for context in contexts:\n",
        "  sampling_new = sampling[sampling[\"board_id\"] == context].reset_index()\n",
        "  for sampling_length in sampling_lengths:\n",
        "    max_samples = len(sampling_new[\"score\"])\n",
        "    temp = sampling_new[\"score\"].to_list()\n",
        "    sampled = sample(temp,sampling_length)\n",
        "    max_eig = max(sampled)\n",
        "    zero = Counter(sampled)[0]/len(sampled)\n",
        "    df_dict[\"model\"].append(\"Grammar\")\n",
        "    df_dict[\"sample_length\"].append(sampling_length)\n",
        "    df_dict[\"attributes\"].append(sampling_length)\n",
        "    df_dict[\"context\"].append(context)\n",
        "    df_dict[\"max_eig\"].append(max_eig)\n",
        "    df_dict[\"valid\"].append(1-zero)\n",
        "    print(\"Grammar\",sampling_length, sampling_length, context,max_eig, zero)\n",
        "\n",
        "df = pd.DataFrame.from_dict(df_dict)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c092JbC91DF",
        "outputId": "abcc5e76-200b-45a8-b1e9-edf377b26810"
      },
      "outputs": [],
      "source": [
        "#This cell computes the standard deviations to complete Table 1\n",
        "#This is meant to be copied and pasted into a LaTeX file so the DataFrame stores everything as a string, and the plus-or-minus symbols are indicated by underscores\n",
        "from math import sqrt\n",
        "\n",
        "df_dict = {\"model\":[],\"samples\":[],\"avg_valid\":[],\"avg_eig\":[]}\n",
        "\n",
        "samples = [10,100,1000,10000]\n",
        "for sample in samples:\n",
        "  current = df[df[\"model\"]==\"Grammar\"][df[\"sample_length\"]==sample]\n",
        "\n",
        "  eigList = current[\"max_eig\"].to_list()\n",
        "  avgEig = sum(eigList)/len(eigList)\n",
        "\n",
        "  stdDev = sqrt(sum([(i-avgEig)**2 for i in eigList])/len(eigList))\n",
        "  avgValidity = sum(current[\"valid\"].to_list())/len(current[\"valid\"].to_list())\n",
        "\n",
        "  df_dict[\"model\"].append(\"sampling\")\n",
        "  df_dict[\"samples\"].append(str(sample))\n",
        "  df_dict[\"avg_valid\"].append(str(avgValidity))\n",
        "  df_dict[\"avg_eig\"].append(str(avgEig)+\"_\"+str(stdDev))\n",
        "  print(\" \".join([\"sampling\",str(sample),str(avgValidity),str(avgEig)+\"_\"+str(stdDev)]))\n",
        "\n",
        "samples = [10,100]\n",
        "models = [\"ascii\",\"serial\",\"vision\"]\n",
        "for sample in samples:\n",
        "  for model in models:\n",
        "    current = df[df[\"model\"]==\"GPT4\"][df[\"sample_length\"]==str(sample)][df[\"attributes\"] == model]\n",
        "    eigList = current[\"max_eig\"].to_list()\n",
        "    avgEig = sum([float(i) for i in eigList])/len(eigList)\n",
        "    stdDev = sqrt(sum([(float(i)-avgEig)**2 for i in eigList])/len(eigList))\n",
        "    avgValidity = sum(current[\"valid\"].to_list())/len(current[\"valid\"].to_list())\n",
        "\n",
        "    df_dict[\"model\"].append(\"llm\"+\"_\"+model)\n",
        "    df_dict[\"samples\"].append(str(sample))\n",
        "    df_dict[\"avg_valid\"].append(str(avgValidity))\n",
        "    df_dict[\"avg_eig\"].append(str(avgEig)+\"_\"+str(stdDev))\n",
        "    print(\" \".join([\"llm\"+\"_\"+model,str(sample),str(avgValidity),str(avgEig)+\"_\"+str(stdDev)]))\n",
        "\n",
        "particles = [1,3,5]\n",
        "models = [\"REGULAR\",\"COMBINED\"]\n",
        "for model in models:\n",
        "  for particle in particles:\n",
        "    att = f\"{model}_{particle}\"\n",
        "    extra = \"(No board)\" if model == \"REGULAR\" else \"\"\n",
        "    current = df[df[\"model\"]==f'SMC Steering {extra}'][df[\"attributes\"] == att]\n",
        "    eigList = current[\"max_eig\"].to_list()\n",
        "    avgEig = sum([float(i) for i in eigList])/len(eigList)\n",
        "    stdDev = sqrt(sum([(float(i)-avgEig)**2 for i in eigList])/len(eigList))\n",
        "    samplesList = current[\"sample_length\"].to_list()\n",
        "    avgSamples = sum(samplesList)/len(samplesList)\n",
        "    samplesSD = sqrt(sum([(float(i)-avgSamples)**2 for i in samplesList])/len(samplesList))\n",
        "    avgValidity = sum(current[\"valid\"].to_list())/len(current[\"valid\"].to_list())\n",
        "\n",
        "    df_dict[\"model\"].append(\"SMC\"+str(particle)+\"_\"+model)\n",
        "    df_dict[\"samples\"].append(str(avgSamples)+\"_\"+str(samplesSD))\n",
        "    df_dict[\"avg_valid\"].append(str(avgValidity))\n",
        "    df_dict[\"avg_eig\"].append(str(avgEig)+\"_\"+str(stdDev))\n",
        "    print(\" \".join([\"SMC\"+str(particle)+\"_\"+model,str(avgSamples)+\"_\"+str(samplesSD),str(avgValidity),str(avgEig)+\"_\"+str(stdDev)]))\n",
        "\n",
        "df_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "iRaOBOJjZ3UL",
        "outputId": "e696d73d-2b82-4e1d-9d3b-05d3f8823df9"
      },
      "outputs": [],
      "source": [
        "#This cell generates Figure 1 from the data.\n",
        "import seaborn as sns\n",
        "from math import log\n",
        "df.to_csv(\"plot_data.csv\")\n",
        "df = df.astype({\"attributes\":str})\n",
        "df_plot = df[[\"sample_length\",\"max_eig\",\"model\"]]\n",
        "df_plot = df_plot.astype({\"sample_length\":float,\"max_eig\":float})\n",
        "df_plot[\"sample_length\"] = [log(i,10) for i in df_plot[\"sample_length\"].to_list()]\n",
        "df_plot = df_plot.rename(columns={\"sample_length\": \"Samples Taken (log₁₀)\", \"max_eig\": \"Maximum EIG\", \"model\":\"Model\"})\n",
        "s = sns.scatterplot(data=df_plot, x='Samples Taken (log₁₀)', y='Maximum EIG',hue=\"Model\")\n",
        "s.set_ylim(0,5)\n",
        "s = s.set(title=\"Overall Model Informativeness\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
