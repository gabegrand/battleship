{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from battleship.grammar import BattleshipGrammar\n",
    "from battleship.scoring import compute_score, compute_score_parallel\n",
    "from battleship.board import Board\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = BattleshipGrammar(include_lambdas=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from math import ceil\n",
    "\n",
    "dataDict = {\n",
    "    'program':[],\n",
    "    'board_id':[],\n",
    "    'score':[],\n",
    "    'max_depth':[],\n",
    "    'sample_length':[]\n",
    "}\n",
    "df = pd.DataFrame(dataDict)\n",
    "\n",
    "if not os.path.isfile('enumData.csv'):\n",
    "   df.to_csv('enumData.csv', header='column_names')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_baseline(cores=int(os.cpu_count()/2),sample_length=5,depth=8):\n",
    "    scores = []\n",
    "    for id in range(1,18+1):\n",
    "        start_time = time.time()\n",
    "        print(f\"board {id}\", end=\" | \") \n",
    "        acceptable_programs = []\n",
    "        while len(acceptable_programs) != sample_length: #Rejection sampling of {sample_length} programs of depth {max_depth}\n",
    "            try:\n",
    "                program = grammar.sample(depth)\n",
    "            except:\n",
    "                continue\n",
    "            if program != None: #Sometimes the grammar returns a NoneType (bug?) so this is necessary \n",
    "                if \"(\" in program or \")\" in program: #Ignores all single-token questions: a single-token question won't have brackets, so if we know a response has brackets, it is not single-token. \n",
    "                #A more robust \"min-depth\" parameter would parse the generated program, but this will do for one-token answers \n",
    "                    acceptable_programs.append(program)\n",
    "        print(f\"finished generating programs in {round(time.time()-start_time,2)}s\", end=\" | \")\n",
    "     \n",
    "        if cores != 1:\n",
    "            #If more than one core is used, breaks it up into chunks of 50 programs to score in parallel as to not overwork the machine and kill the EC2 instance or the kernel.\n",
    "            for i in range(ceil(sample_length/50)):\n",
    "                program_scores = compute_score_parallel(programs=acceptable_programs[i*50:((i+1)*50)],board=Board.from_trial_id(id),processes=cores,show_progress=False)\n",
    "                scores.extend(program_scores)\n",
    "                dataDict['program'].extend(acceptable_programs[i*50:((i+1)*50)])\n",
    "                dataDict['board_id'].extend([id for i in range(len(program_scores))])\n",
    "                dataDict['score'].extend(program_scores)\n",
    "                dataDict['max_depth'].extend([depth for i in range(len(program_scores))])\n",
    "                dataDict['sample_length'].extend([sample_length for i in range(len(program_scores))])\n",
    "        else:\n",
    "            #If only one core is used, computes programs scores sequentially\n",
    "            for prog in acceptable_programs:\n",
    "                score = compute_score(program=prog, board=Board.from_trial_id(id))\n",
    "                scores.append(score)\n",
    "        print(f\"finished scoring in {round(time.time()-start_time,2)}s from the start\")\n",
    "\n",
    "    df = pd.DataFrame(dataDict)\n",
    "    df.to_csv('sampleData.csv', mode='a', header=False)\n",
    "    print(f\"finished {sample_length}-shot sampling at depth {depth}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [1,5,10,20,25,50,100,250,500,1000,2000]\n",
    "depths = [5,6,7,8,9,10]\n",
    "\n",
    "for depth in depths:\n",
    "    for sample_num in samples:\n",
    "        sample_baseline(sample_length=sample_num,depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"enumData.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
